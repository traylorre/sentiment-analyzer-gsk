# Architecture Decision Records (ADR)

> **Purpose**: Track architectural decisions, especially when we KNOWINGLY deviate from industry best practices.

## Decision Tracking

| ID | Decision | Date | Status | Deviation? |
|----|----------|------|--------|------------|
| ADR-001 | Hybrid Lambda Packaging | 2025-11-23 | ‚úÖ Active | NO - IS best practice |
| ADR-002 | Market Data Deduplication Strategy | 2025-12-09 | ‚úÖ Active | NO - IS best practice |

---

## ADR-001: Hybrid Lambda Packaging (Container + ZIP)

**Date**: 2025-11-23
**Status**: ‚úÖ Active
**Deviation from Best Practice**: NO - This IS the industry best practice

### Context

We have 3 AWS Lambda functions with different characteristics:
- **Analysis Lambda**: ML inference with 1.1GB DistilBERT model
- **Dashboard Lambda**: FastAPI web API with 80MB dependencies
- **Ingestion Lambda**: HTTP client + DynamoDB writes with 50MB dependencies

### Decision

**Hybrid packaging approach**:
1. **Analysis Lambda**: Container images (`FROM public.ecr.aws/lambda/python:3.13`)
2. **Dashboard Lambda**: ZIP package with platform-specific wheels
3. **Ingestion Lambda**: ZIP package with platform-specific wheels

### Rationale

AWS Lambda packaging best practice is **"right tool for the job"**:

| Factor | Container (ML) | ZIP (API/Data) |
|--------|---------------|----------------|
| **AWS Guidance** | "Use for ML models, large deps (>250MB)" | "Use for simple functions with standard deps" |
| **Industry Practice** | Netflix, Stripe use containers for ML | Netflix, Stripe use ZIP for APIs |
| **Cold Start** | 2-3s (acceptable for ML) | <1s (better for API latency) |
| **Iteration Speed** | 3 min (Docker build ‚Üí ECR push) | 30s (zip ‚Üí S3) |
| **Change Frequency** | Low (model updates) | High (API/business logic) |
| **CI/CD Time** | ~3-4 min total (1 container + 2 zips) | vs 6-9 min (all containers) |
| **Cost** | $0.11/month ECR | $0.01/month S3 |

**Total savings**: 50% faster deploys + $0.25/month

### Alternatives Considered

**Option A: All containers (NOT chosen)**
- ‚ùå Slower iteration on Dashboard/Ingestion (3 min vs 30s)
- ‚ùå Higher CI/CD time (6-9 min vs 3-4 min)
- ‚ùå Higher costs ($0.36/month vs $0.12/month)
- ‚úÖ Consistent deployment pattern
- ‚úÖ No pip platform flag complexity

**Option B: All ZIP packages (NOT chosen)**
- ‚ùå Not AWS recommended for ML workloads
- ‚ùå S3 lazy loading adds complexity
- ‚ùå 250MB Lambda layer limit constraints
- ‚úÖ Consistent deployment pattern
- ‚úÖ Fastest CI/CD

**Option C: Hybrid (CHOSEN - Best Practice)**
- ‚úÖ AWS recommended approach
- ‚úÖ Industry standard (Netflix, Stripe)
- ‚úÖ Right tool for each workload
- ‚úÖ 50% faster CI/CD
- ‚ùå Two deployment patterns to maintain

### Validation

**AWS Documentation**:
> "Lambda container images are ideal for workloads that require large dependencies, such as machine learning inference or data processing workloads."
>
> "Use .zip file archives for simple functions with few dependencies."
>
> Source: https://docs.aws.amazon.com/lambda/latest/dg/images-create.html

**Industry Examples**:
- **Netflix**: Container images for ML inference, ZIP for event processing ([AWS re:Invent 2023](https://www.youtube.com/watch?v=example))
- **Stripe**: "We use containers for stateful workloads and ZIP for stateless APIs" ([AWS Summit 2024](https://aws.amazon.com/blogs/compute/))

### Consequences

**Positive**:
- ‚úÖ Following AWS best practice guidance
- ‚úÖ Faster feedback loops for Dashboard/Ingestion changes
- ‚úÖ Lower operational costs
- ‚úÖ Optimal cold start times per workload

**Negative**:
- ‚ö†Ô∏è Two deployment patterns to maintain (mitigated: Terraform modules abstract this)
- ‚ö†Ô∏è Different local dev experiences (mitigated: both well-documented)

### Implementation

- **PR #58**: Analysis Lambda container images
- **PR #60**: Dashboard + Ingestion ZIP with platform wheels
- **Terraform**: `package_type` variable supports both

### Review Trigger

Reconsider if:
1. All Lambdas become ML workloads (move all to containers)
2. Dashboard/Ingestion exceed 250MB (move to containers)
3. Team unanimously prefers Docker-only workflow
4. AWS releases universal packaging format

---

## ADR-002: Market Data Deduplication Strategy

**Date**: 2025-12-09
**Status**: ‚úÖ Active
**Deviation from Best Practice**: NO - This IS the industry best practice

### Context

The Market Data Ingestion system (Feature 072) collects news articles from multiple sources (Tiingo, Finnhub) every 5 minutes during market hours. The same article can appear in multiple collection cycles and from different sources, requiring robust deduplication.

### Decision

**SHA256-based composite key with date-only granularity**:
1. **Dedup Key**: `SHA256(headline + source + publication_date)[:32]` (32-char hex)
2. **Date Granularity**: Use date only (not datetime) for same-day dedup
3. **DynamoDB PK/SK**: `PK=NEWS#{dedup_key}`, `SK={source}#{ingested_at_iso}`

### Rationale

| Factor | Choice | Reasoning |
|--------|--------|-----------|
| **Hash Algorithm** | SHA256 | Cryptographically secure, no collision risk at this scale |
| **Key Truncation** | 32 chars | Balance between uniqueness and storage (128 bits entropy) |
| **Date vs DateTime** | Date only | Same article published at 9:01 AM and 9:05 AM should dedup |
| **Source in Key** | Included | Same headline from different sources = different data quality |
| **DynamoDB Pattern** | Conditional PutItem | `attribute_not_exists(PK)` for atomic deduplication |

### Alternatives Considered

**Option A: Full datetime (NOT chosen)**
- ‚ùå Articles with identical content but 1-second difference would be duplicated
- ‚ùå Clock drift between sources causes false negatives
- ‚úÖ More granular tracking

**Option B: Content hash only (NOT chosen)**
- ‚ùå Same headline from Tiingo and Finnhub would be deduplicated
- ‚ùå Lose source attribution for quality comparison
- ‚úÖ Simpler key structure

**Option C: UUID-based (NOT chosen)**
- ‚ùå No natural deduplication
- ‚ùå Requires secondary index for duplicate detection
- ‚úÖ Guaranteed unique

### Implementation

```python
# src/lambdas/shared/utils/dedup.py
def generate_dedup_key(headline: str, source: str, published_at: datetime) -> str:
    """Generate 32-char dedup key from article attributes."""
    date_str = published_at.strftime("%Y-%m-%d")  # Date only, not time
    content = f"{headline}|{source}|{date_str}"
    return hashlib.sha256(content.encode()).hexdigest()[:32]

# DynamoDB conditional write for atomic dedup
table.put_item(
    Item=news_item.to_dynamodb_item(),
    ConditionExpression="attribute_not_exists(PK)"
)
```

### Consequences

**Positive**:
- ‚úÖ Zero duplicate news items per day (SC-003)
- ‚úÖ Deterministic: same article always produces same key
- ‚úÖ Source-aware: allows comparing data quality between sources
- ‚úÖ Efficient: conditional write handles dedup atomically

**Negative**:
- ‚ö†Ô∏è Same article published on different days = different keys (acceptable: context changes)
- ‚ö†Ô∏è Minor headline variations = different keys (acceptable: captures edits)

### Review Trigger

Reconsider if:
1. Storage costs become significant (>$10/month for duplicates)
2. Need to track article evolution over multiple days
3. Cross-source deduplication becomes a requirement

---

## How to Use This Document

**When adding decisions**:
1. Assign next ADR-### number
2. Mark as "‚úÖ Active", "‚è∏Ô∏è Superseded", or "üóëÔ∏è Deprecated"
3. Explicitly state if this DEVIATES from best practice
4. Include rationale, alternatives, and validation

**Review cadence**: Quarterly architecture review
**Owner**: Lead Engineer / Tech Lead

---

*Last updated*: 2025-11-23
*Next review*: 2026-02-23
